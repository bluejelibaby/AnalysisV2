
* SUSYNTUPLA v2 User's Guide
** Setup
***  Installation and Configuration
     Once you have extracted the source code to a folder of your choice, open
     the file setup.(c)sh in a text editor. Change the value of the variable,
     SUSY\_WORKING\_SW\_DIR to the absolute path of the folder containing the
     SUSYNTUPLA code. It should look something like this:
#+BEGIN_SRC make
     setenv SUSY_WORKING_SW_DIR $HOME/susy_code
#+END_SRC

     You may also alter the other variables to change the version of ROOT you
     are using or the Python path. If you are running on LXPLUS, these should
     already be correctly set. If you are running on your own machine, you may
     need to change the value of MY\_ROOTSYS.

     Finally, open the file config.inc. If you are running on LXPLUS, these
     values should be set correctly. If you are running on your own machine, you
     may need to change them. This will depend on how ROOT is installed on your
     machine. For Ubuntu, I have:
#+BEGIN_SRC make
     ROOTSYS_INC=/usr/include/root
     ROOTSYS_LIB=/usr/lib
     ROOTSYS_BIN=/usr/bin
     PYTHON_INC=/usr/include/python2.6
     PYTHON_LIB=-lpython2.6
     BOOST_PYTHON_LIB=-lboost_python-mt
#+END_SRC

     For LXPLUS, it should be:
#+BEGIN_SRC make
     ROOTSYS_INC=$(ROOTSYS)/include
     ROOTSYS_LIB=$(ROOTSYS)/lib
     ROOTSYS_BIN=$(ROOTSYS)/bin
     PYTHON_INC=/usr/include/python2.3
     PYTHON_LIB=-lpython2.3
     BOOST_PYTHON_LIB=-lboost_python-mt
#+END_SRC

     Now, everything should be configured correctly. Simply source the file
     setup.(c)sh and your environment will be setup.

*** Compiling
    The code structure for V2 of the code has changed. Common aspects of the
    code are in the directory framework/. These are compiled into a shared
    library which libFrameworkSUSY.so which can then be linked against your own
    analysis code. All code specific to a given analysis should reside in a
    separate folder within the SUSY code structure. For instance the single
    lepton analysis would reside in the folder onelepton. Each analysis' code is
    built into a separate shared library which will be stored in the lib/ folder
    in the root of the codebase. Each module has two makefiles Debug and
    Release. Most of the time, the Debug file should be used so that the
    resulting library can be debugged.

    In order to build the onelepton module, you must first build the core
    framework by changing in to the framework directory and typing:

#+BEGIN_SRC bash
    make -f Debug
#+END_SRC

    This compiles the core framework code. This should only be needed when the
    core code has been changed. NOTE: You do not need to make clean. To compile
    the onelepton code itself, change to the onelepton directory and type the
    same command.

** The Code
*** The core
    The V2 code is different in many respects to V1. The most important change
    is that variables are now cached and loaded/calculated on demand. All
    variables within the core code (e.g. CommonJets, MET, MHT) are now contained
    within a descendent of the Compute::Variable class. This class takes care of
    all the caching for you. When you try to access the variable
    e.g. CommonJets, you will now call a function. This function checks if the
    variable has already been calculated for the current event. If it has, it
    simply returns it. If not, then it will calculate it from scratch. In so
    doing it may have to access other variables which in turn will be
    calculated. In addition, it may have to access branches of the ntuple. These
    are encapsulated by the Event::Element class which will read the quantity
    from the ntuple and return it.

    This may seem like a huge complication but the advantage is that when you
    request a given variable, the code will perform the minimum possible
    calculations and ntuple I/O to satisfy the request. This gives huge speed
    improvements over the old code in many cases.

    In addition, the caching mechanism can be used within operations to define
    your own custom variables. This is done using the Compute::User
    class. Variables defined in this way can be loaded by any Operation class
    that needs them. They will be calculated only once per event and may be
    shared between several Operation classes.

*** The Python.cc file
    This file is used to expose the operations defined in your shared library so
    that they can be accessed from a Python script. The magic that connects C++
    to Python is done by the BOOST Python library so you should look at [[http://www.boost.org/doc/libs/1_41_0/libs/python/doc/index.html][the
    manual]] for proper documentation.

    The essential element of this file is the class\_ directive. This has the
    following syntax:
#+BEGIN_SRC c++
    class_<ClassName,bases<BaseClassName>("PythonName",init<ArgType1,ArgType2...>());
#+END_SRC

    This tells Python that the C++ class ClassName should be exposed as the
    Python class PythonName with a constructor that takes ArgType1,
    ArgType2... as arguments. It also tells Python that the class ClassName
    inherits from BaseClassName. For the purposes of simply exposing an
    operation to Python, this should be enough. So to expose the NumComMuons
    operation we do the following:
#+BEGIN_SRC c++
    class_<Operation::NumComMuons, bases<Operation::_Base> >("OP_NumComMuons",
							   init<const std::string &,
							   UInt_t>());
#+END_SRC

    This tells Python to register the class NumComMuons in the Operation
    namespace as Python class OP\_NumComMuons. The constructor will take a
    reference to a string and an unsinged integer. Also, the operation will inherit
    from the Operation::\_Base class.

    Once you have done this, simply rebuild the module and the class will be
    available from Python.


** Frequently Asked Questions
*** I get weird Symbol Not Found errors
    These look a lot more confusing than they actually are. They occur because
    when the code is built as a shared library it will not complain about not
    being able to find bits of your code (since they may be in another shared
    library).

    To decipher them, use the c++filt command to untangle the problematic symbol
    name.
#+BEGIN_SRC bash
    c++filt <symbol_name>
#+END_SRC
    This will tell you where the problem is in your code.
